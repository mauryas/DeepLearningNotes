{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "* pickle - Used for importing created features\n",
    "* numpy - Used for working with arrays\n",
    "* TensorFlow - For creating deep neural network graphs and later processing them\n",
    "* Keras ImageDataGenerator - Used for randomly changing input data for more robust learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the data\n",
    "The data is already pre-processed and we are just using mixture of horizontal and vertical data. This has provided me better classification result when compared against using only horizontal or vartical. Also, the performance is comparable (but not better :/) if we combine horizontal, verticle and summed horizontal and vertical images. But it reduces the size of our network. \n",
    "* provide the path of pickle files\n",
    "* Load and convert the data into numpy arrays/matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_train = open(\"train.pickle\",\"rb\")\n",
    "pickle_valid = open(\"valid.pickle\",\"rb\")\n",
    "\n",
    "trainX = pickle.load(pickle_train)\n",
    "validX = pickle.load(pickle_valid)\n",
    "\n",
    "X_train = np.array(trainX['xtrain'],dtype=np.float32)\n",
    "X_valid = np.array(validX['xvalid'],dtype=np.float32)\n",
    "\n",
    "y_train = np.array(trainX['ytrain'],dtype=np.int32)\n",
    "y_valid = np.array(validX['yvalid'],dtype=np.int32)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "datagen.fit(X_train.reshape([-1,75,75,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Global Variables\n",
    "Create some global variables/parameters used by our network.\n",
    "* image_size - size of images, here 75 x 75\n",
    "* n_class - one hot encoding of iceberg or ship\n",
    "* batch_size - size of the batch which will be supplied to train our network. Using 32 as it create a medium sized tensors but if I use a bigger batch size (62, 128 etc), the size of tensors get large and problematic to train on my laptop.\n",
    "* epocs - No. of times the network sees the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 75\n",
    "n_class = 2\n",
    "batch_size = 32\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Design the Graph\n",
    "----------------------------\n",
    "### 4.1 Methods\n",
    "Some helpful functions which will be repeatedly used while creating the graphs:\n",
    "* weight_variable: initializes weights. Using Xavier Initialization as provides better starting weights than initializing with other techniques and results in faster converging solutions.\n",
    "    * inputs shape of tensor and name for the variable\n",
    "* bias_variable: creates bias variable. Initialize it with small constant weight.\n",
    "    * inputs size based on weight and name of the bias\n",
    "* conv2d: creates a 2D convolutional layer with stride as [1,1,1,1] and padding as same\n",
    "    * inputs the tensor (original or from previous layer) and weights of the layer.\n",
    "* max_pool: max pooling layer with a 3 x 3 window size. Helpful in reducing the dimension.\n",
    "    * inputs the tensor (original or from previous layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape,nm):\n",
    "  initial = tf.contrib.layers.xavier_initializer()\n",
    "  return tf.get_variable(nm,shape=shape,initializer=initial)\n",
    "\n",
    "def bias_variable(shape,nm):\n",
    "  initial = tf.constant(0.1, shape=shape,name=nm)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x,stride):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 3, 3, 1],\n",
    "                        strides=stride, padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Input Placeholders\n",
    "Create placeholders for passing input and output while processing the graph at runtime. 'None' helps in creating dynamic shapes which gets initialized during runtime. It will depend on the size of input. So, while training our batch is 32, x will be a tensor of shape [32,75,75,1] and [32,2] for y_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, n_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Hidden Layer 1 \n",
    "In first layer a window of 5X5 is convoluted over the input image. The first step gives us output of shape of [32,75,75,32] which is then passed into a relu activation function. After that we perform max pool across 3x3 window and this gives us [32,25,25,32]. h_pool1 is the output of the first convolution layer which will passed to another convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32],\"W1\")\n",
    "b_conv1 = bias_variable([32],\"b1\")\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool(h_conv1,[1,3,3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Hidden Layer 2 \n",
    "Again a window of 5X5 is convoluted over the input image. This step gives us output of shape of [32,25,25,64] which is then passed into a relu activation function. After that we perform max pool across 3x3 window and this gives us [32,9,9,64]. h_pool2 is passed into the inception layer.\n",
    "> Replacing this layer by another inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5,5,32,64],'W2')\n",
    "b_conv2 = bias_variable([64],'b2')\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool(h_conv2,[1,3,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W_iconv1_1x1_1 = weight_variable([1,1,32,16],'W_i1c1')\n",
    "# b_iconv1_1x1_1 = bias_variable([16],'b_i1c1')\n",
    "\n",
    "# W_iconv1_1x1_2 = weight_variable([1,1,32,8],'W_i1c2')\n",
    "# b_iconv1_1x1_2 = bias_variable([8],'b_i1c2')\n",
    "\n",
    "# W_iconv1_1x1_3 = weight_variable([1,1,32,8],'W_i1c3')\n",
    "# b_iconv1_1x1_3 = bias_variable([8],'b_i1c3')\n",
    "\n",
    "# W_iconv1_3x3 = weight_variable([3,3,8,16],'W_i1c4')\n",
    "# b_iconv1_3x3 = bias_variable([16],'b_i1c4')\n",
    "\n",
    "# W_iconv1_5x5 = weight_variable([5,5,8,16],'W_i1c5')\n",
    "# b_iconv1_5x5 = bias_variable([16],'b_i1c5')\n",
    "\n",
    "# W_iconv1_1x1_4 = weight_variable([1,1,32,16],'W_i1c6')\n",
    "# b_iconv1_1x1_4 = bias_variable([16],'b_i1c6')\n",
    "\n",
    "# h_conv1_1x1_1 = conv2d(h_pool1,W_iconv1_1x1_1) + b_iconv1_1x1_1\n",
    "# h_conv1_1x1_2 = tf.nn.relu(conv2d(h_pool1,W_iconv1_1x1_2)+b_iconv1_1x1_2)\n",
    "# h_conv1_1x1_3 = tf.nn.relu(conv2d(h_pool1,W_iconv1_1x1_3)+b_iconv1_1x1_3)\n",
    "# h_conv1_3x3 = conv2d(h_conv1_1x1_2,W_iconv1_3x3)+b_iconv1_3x3\n",
    "# h_conv1_5x5 = conv2d(h_conv1_1x1_3,W_iconv1_5x5)+b_iconv1_5x5\n",
    "# h_maxpool1 = max_pool(h_pool1,[1,1,1,1])\n",
    "# h_conv1_1x1_4 = conv2d(h_maxpool1,W_iconv1_1x1_4)+ b_iconv1_1x1_4\n",
    " \n",
    "# h_pool_incep = max_pool(tf.concat([h_conv1_1x1_1,h_conv1_3x3,h_conv1_5x5,h_conv1_1x1_4],3),[1,3,3,1])\n",
    "# inception = tf.nn.relu(h_pool_incep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Hidden Layer 3\n",
    "Lets add a layer from Inception model used by google. The model consists of 4 1x1 convolution layer, a 3x3 and a 5x5 convolution layer. The first 3 1x1 layer take the input from the previous convoluted layer. The 3x3 and 5x5 layers take input from 2 of the 1x1 convolution layers. The remaining 1x1 conv layer is get input from the  max pool of the previous layer. Finally, the ouput from the layers are combined, then passed through a max pool and relu. The output from this inception module is flattened and passed in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_iconv_1x1_1 = weight_variable([1,1,64,64],'W_ic1')\n",
    "b_iconv_1x1_1 = bias_variable([64],'b_ic1')\n",
    "\n",
    "W_iconv_1x1_2 = weight_variable([1,1,64,32],'W_ic2')\n",
    "b_iconv_1x1_2 = bias_variable([32],'b_ic2')\n",
    "\n",
    "W_iconv_1x1_3 = weight_variable([1,1,64,32],'W_ic3')\n",
    "b_iconv_1x1_3 = bias_variable([32],'b_ic3')\n",
    "\n",
    "W_iconv_3x3 = weight_variable([3,3,32,64],'W_ic4')\n",
    "b_iconv_3x3 = bias_variable([64],'b_ic4')\n",
    "\n",
    "W_iconv_5x5 = weight_variable([5,5,32,64],'W_ic5')\n",
    "b_iconv_5x5 = bias_variable([64],'b_ic5')\n",
    "\n",
    "W_iconv_1x1_4 = weight_variable([1,1,32,64],'W_ic6')\n",
    "b_iconv_1x1_4 = bias_variable([64],'b_ic6')\n",
    "\n",
    "h_conv1_1x1_1 = conv2d(h_pool2,W_iconv_1x1_1) + b_iconv_1x1_1\n",
    "h_conv1_1x1_2 = tf.nn.relu(conv2d(h_pool2,W_iconv_1x1_2)+b_iconv_1x1_2)\n",
    "h_conv1_1x1_3 = tf.nn.relu(conv2d(h_pool2,W_iconv_1x1_3)+b_iconv_1x1_3)\n",
    "h_conv1_3x3 = conv2d(h_conv1_1x1_2,W_iconv_3x3)+b_iconv_3x3\n",
    "h_conv1_5x5 = conv2d(h_conv1_1x1_3,W_iconv_5x5)+b_iconv_5x5\n",
    "h_maxpool1 = max_pool(h_pool1,[1,3,3,1])\n",
    "h_conv1_1x1_4 = conv2d(h_maxpool1,W_iconv_1x1_4)+ b_iconv_1x1_4\n",
    " \n",
    "#concatenate all the feature maps and then pass through max pool and relu.\n",
    "h_pool_incep = tf.concat([h_conv1_1x1_1,h_conv1_3x3,h_conv1_5x5,h_conv1_1x1_4],3)#max_pool(tf.concat([h_conv1_1x1_1,h_conv1_3x3,h_conv1_5x5,h_conv1_1x1_4],3),[1,3,3,1])\n",
    "inception = tf.nn.relu(h_pool_incep)\n",
    "\n",
    "h_fc_flat = tf.reshape(inception,[-1,9*9*256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W_i2conv_1x1_1 = weight_variable([1,1,64,64],'W_i2c1')\n",
    "# b_i2conv_1x1_1 = bias_variable([64],'b_i2c1')\n",
    "\n",
    "# W_i2conv_1x1_2 = weight_variable([1,1,64,32],'W_i2c2')\n",
    "# b_i2conv_1x1_2 = bias_variable([32],'b_i2c2')\n",
    "\n",
    "# W_i2conv_1x1_3 = weight_variable([1,1,64,32],'W_i2c3')\n",
    "# b_i2conv_1x1_3 = bias_variable([32],'b_i2c3')\n",
    "\n",
    "# W_i2conv_3x3 = weight_variable([3,3,32,64],'W_i2c4')\n",
    "# b_i2conv_3x3 = bias_variable([64],'b_i2c4')\n",
    "\n",
    "# W_i2conv_5x5 = weight_variable([5,5,32,64],'W_i2c5')\n",
    "# b_i2conv_5x5 = bias_variable([64],'b_i2c5')\n",
    "\n",
    "# W_i2conv_1x1_4 = weight_variable([1,1,64,64],'W_i2c6')\n",
    "# b_i2conv_1x1_4 = bias_variable([64],'b_i2c6')\n",
    "\n",
    "# h_i2conv1_1x1_1 = conv2d(inception,W_i2conv_1x1_1) + b_i2conv_1x1_1\n",
    "# h_i2conv1_1x1_2 = tf.nn.relu(conv2d(inception,W_i2conv_1x1_2)+b_i2conv_1x1_2)\n",
    "# h_i2conv1_1x1_3 = tf.nn.relu(conv2d(inception,W_i2conv_1x1_3)+b_i2conv_1x1_3)\n",
    "# h_i2conv1_3x3 = conv2d(h_i2conv1_1x1_2,W_i2conv_3x3)+b_i2conv_3x3\n",
    "# h_i2conv1_5x5 = conv2d(h_i2conv1_1x1_3,W_i2conv_5x5)+b_i2conv_5x5\n",
    "# h_i2maxpool1 = max_pool(inception,[1,1,1,1])\n",
    "# h_i2conv1_1x1_4 = conv2d(h_i2maxpool1,W_i2conv_1x1_4)+ b_i2conv_1x1_4\n",
    " \n",
    "# #concatenate all the feature maps and hit them with a relu\n",
    "# h_i2pool_incep = max_pool(tf.concat([h_i2conv1_1x1_1,h_i2conv1_3x3,h_i2conv1_5x5,h_i2conv1_1x1_4],3),[1,3,3,1])\n",
    "# inception2 = tf.nn.relu(h_i2pool_incep)\n",
    "\n",
    "# h_fc_flat = tf.reshape(inception2,[-1,3*3*256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Hidden Layer 4\n",
    "After the convolutional and inception layers, we will add fully connected layers. Output is of size [32,2048]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([9*9*256, 2048],\"W3\")\n",
    "b_fc1 = bias_variable([2048],\"b2\")\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_fc_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Hidden Layer 5\n",
    "Another fully connected layer with droput. Adding dropout for more roboust learning by the layer. Output with shape [32, 704]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W_fc2 = weight_variable([2048,704],'W4')\n",
    "b_fc2 = bias_variable([704],'b4')\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1,W_fc2) + b_fc2)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2,drop_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Output Layer\n",
    "Final Layer which will provide the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc3 = weight_variable([704,n_class],'W5')\n",
    "b_fc3 = bias_variable([n_class],'b5')\n",
    "\n",
    "y_out = tf.matmul(h_fc2_drop,W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Loss, Optimization and Accuracy\n",
    "* Cross entropy between true class y_ and value predict by our model y_out is calculated and then softmax operation is performed. Then mean of the cross entropy over the batch is calculated.  \n",
    "* Among the choices availabe for gradient descent, it's best to use adam optimizer which has momentum and decay function. Among different values I used for learning rate, values around 1e-4 gives the best results.\n",
    "* Accuracy is calculated to quantify the performance of the our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_out))\n",
    "\n",
    "train_optimizer = tf.train.AdamOptimizer(learning_rate=5e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(y_out, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "After designing the NN graph, we will plot some TF graphs for see how our TF network trains and performs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar(name='Loss', tensor=cross_entropy)\n",
    "tf.summary.scalar(name='Accuracy',tensor=accuracy)\n",
    "graph_summary = tf.summary.merge_all()\n",
    "tf_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trainig the NN Graph\n",
    "Intialize the weights, biases and variable for writing summaries into disk. Generate the training and validation data using the Keras image data generator and pass for training and validation.\n",
    "Lets train our network and find how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 \n",
      " - Batch no: 0, train accuracy: 0.5\n",
      " - Batch no: 10, train accuracy: 0.6875\n",
      " - Batch no: 20, train accuracy: 0.5\n",
      "-Validation accuracy after epoc: 0.6359102129936218 \n",
      "Epoch:1 \n",
      " - Batch no: 0, train accuracy: 0.59375\n",
      " - Batch no: 10, train accuracy: 0.625\n",
      " - Batch no: 20, train accuracy: 0.59375\n",
      "-Validation accuracy after epoc: 0.6234413385391235 \n",
      "Epoch:2 \n",
      " - Batch no: 0, train accuracy: 0.59375\n",
      " - Batch no: 10, train accuracy: 0.71875\n",
      " - Batch no: 20, train accuracy: 0.65625\n",
      "-Validation accuracy after epoc: 0.5112219452857971 \n",
      "Epoch:3 \n",
      " - Batch no: 0, train accuracy: 0.65625\n",
      " - Batch no: 10, train accuracy: 0.625\n",
      " - Batch no: 20, train accuracy: 0.625\n",
      "-Validation accuracy after epoc: 0.6234414577484131 \n",
      "Epoch:4 \n",
      " - Batch no: 0, train accuracy: 0.6875\n",
      " - Batch no: 10, train accuracy: 0.5625\n",
      " - Batch no: 20, train accuracy: 0.6875\n",
      "-Validation accuracy after epoc: 0.6384040117263794 \n",
      "Epoch:5 \n",
      " - Batch no: 0, train accuracy: 0.6875\n",
      " - Batch no: 10, train accuracy: 0.59375\n",
      " - Batch no: 20, train accuracy: 0.53125\n",
      "-Validation accuracy after epoc: 0.6234414577484131 \n",
      "Epoch:6 \n",
      " - Batch no: 0, train accuracy: 0.46875\n",
      " - Batch no: 10, train accuracy: 0.65625\n",
      " - Batch no: 20, train accuracy: 0.75\n",
      "-Validation accuracy after epoc: 0.6209476590156555 \n",
      "Epoch:7 \n",
      " - Batch no: 0, train accuracy: 0.78125\n",
      " - Batch no: 10, train accuracy: 0.75\n",
      " - Batch no: 20, train accuracy: 0.65625\n",
      "-Validation accuracy after epoc: 0.6683291792869568 \n",
      "Epoch:8 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.71875\n",
      " - Batch no: 20, train accuracy: 0.65625\n",
      "-Validation accuracy after epoc: 0.6408977508544922 \n",
      "Epoch:9 \n",
      " - Batch no: 0, train accuracy: 0.59375\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.75\n",
      "-Validation accuracy after epoc: 0.7032418847084045 \n",
      "Epoch:10 \n",
      " - Batch no: 0, train accuracy: 0.625\n",
      " - Batch no: 10, train accuracy: 0.6875\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.700748085975647 \n",
      "Epoch:11 \n",
      " - Batch no: 0, train accuracy: 0.6875\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.71875\n",
      "-Validation accuracy after epoc: 0.7182044982910156 \n",
      "Epoch:12 \n",
      " - Batch no: 0, train accuracy: 0.625\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.78125\n",
      "-Validation accuracy after epoc: 0.7356608510017395 \n",
      "Epoch:13 \n",
      " - Batch no: 0, train accuracy: 0.65625\n",
      " - Batch no: 10, train accuracy: 0.53125\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.7406483888626099 \n",
      "Epoch:14 \n",
      " - Batch no: 0, train accuracy: 0.71875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.78125\n",
      "-Validation accuracy after epoc: 0.7331671118736267 \n",
      "Epoch:15 \n",
      " - Batch no: 0, train accuracy: 0.625\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.7855361700057983 \n",
      "Epoch:16 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8079801201820374 \n",
      "Epoch:17 \n",
      " - Batch no: 0, train accuracy: 0.71875\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.78125\n",
      "-Validation accuracy after epoc: 0.8129675984382629 \n",
      "Epoch:18 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.71875\n",
      "-Validation accuracy after epoc: 0.8329177498817444 \n",
      "Epoch:19 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.852867841720581 \n",
      "Epoch:20 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8079801201820374 \n",
      "Epoch:21 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.71875\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8329177498817444 \n",
      "Epoch:22 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8553617596626282 \n",
      "Epoch:23 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8453865647315979 \n",
      "Epoch:24 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.827930212020874 \n",
      "Epoch:25 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8528677821159363 \n",
      "Epoch:26 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8428927659988403 \n",
      "Epoch:27 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:28 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.857855498790741 \n",
      "Epoch:29 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8453866243362427 \n",
      "Epoch:30 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.78125\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:31 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:32 \n",
      " - Batch no: 0, train accuracy: 0.78125\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.835411548614502 \n",
      "Epoch:33 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8628429770469666 \n",
      "Epoch:34 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8728179931640625 \n",
      "Epoch:35 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:36 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:37 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:38 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8528679013252258 \n",
      "Epoch:39 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.75\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:40 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8778055906295776 \n",
      "Epoch:41 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:42 \n",
      " - Batch no: 0, train accuracy: 0.78125\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.827930212020874 \n",
      "Epoch:43 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:44 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:45 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:46 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:47 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:48 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.850374162197113 \n",
      "Epoch:49 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:50 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:51 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8528679013252258 \n",
      "Epoch:52 \n",
      " - Batch no: 0, train accuracy: 0.78125\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8528679013252258 \n",
      "Epoch:53 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8578553199768066 \n",
      "Epoch:54 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8503741025924683 \n",
      "Epoch:55 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8628429174423218 \n",
      "Epoch:56 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:57 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8678303956985474 \n",
      "Epoch:58 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8578554391860962 \n",
      "Epoch:59 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8453866243362427 \n",
      "Epoch:60 \n",
      " - Batch no: 0, train accuracy: 0.78125\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8478804230690002 \n",
      "Epoch:61 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8753117322921753 \n",
      "Epoch:62 \n",
      " - Batch no: 0, train accuracy: 0.78125\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:63 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:64 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8628429174423218 \n",
      "Epoch:65 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8678304553031921 \n",
      "Epoch:66 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:67 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:68 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.857855498790741 \n",
      "Epoch:69 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8603492379188538 \n",
      "Epoch:70 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8653367757797241 \n",
      "Epoch:71 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8503741025924683 \n",
      "Epoch:72 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:73 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:74 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:75 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8778055310249329 \n",
      "Epoch:76 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8778054714202881 \n",
      "Epoch:77 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8753117918968201 \n",
      "Epoch:78 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8678304553031921 \n",
      "Epoch:79 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:80 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.75\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8728179931640625 \n",
      "Epoch:81 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:82 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8628429770469666 \n",
      "Epoch:83 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.78125\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8703241944313049 \n",
      "Epoch:84 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:85 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:86 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8703243136405945 \n",
      "Epoch:87 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8827930688858032 \n",
      "Epoch:88 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8753117918968201 \n",
      "Epoch:89 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8578553199768066 \n",
      "Epoch:90 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8678305149078369 \n",
      "Epoch:91 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8528679013252258 \n",
      "Epoch:92 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:93 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8578554391860962 \n",
      "Epoch:94 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8478804230690002 \n",
      "Epoch:95 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:96 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8778055310249329 \n",
      "Epoch:97 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:98 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8628430366516113 \n",
      "Epoch:99 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8678304553031921 \n",
      "Epoch:100 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:101 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8678305149078369 \n",
      "Epoch:102 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:103 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:104 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:105 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8603492379188538 \n",
      "Epoch:106 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:107 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8678304553031921 \n",
      "Epoch:108 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8453865647315979 \n",
      "Epoch:109 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8678305149078369 \n",
      "Epoch:110 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8528679013252258 \n",
      "Epoch:111 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8628429174423218 \n",
      "Epoch:112 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:113 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:114 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:115 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8753117322921753 \n",
      "Epoch:116 \n",
      " - Batch no: 0, train accuracy: 0.75\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:117 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:118 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8553615808486938 \n",
      "Epoch:119 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.852867841720581 \n",
      "Epoch:120 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8778054714202881 \n",
      "Epoch:121 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:122 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:123 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:124 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:125 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8628429174423218 \n",
      "Epoch:126 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8678303956985474 \n",
      "Epoch:127 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8753117918968201 \n",
      "Epoch:128 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8603492379188538 \n",
      "Epoch:129 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8802993297576904 \n",
      "Epoch:130 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8453865647315979 \n",
      "Epoch:131 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.862842857837677 \n",
      "Epoch:132 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.8628429174423218 \n",
      "Epoch:133 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:134 \n",
      " - Batch no: 0, train accuracy: 0.8125\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8703243136405945 \n",
      "Epoch:135 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.8125\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.8578554391860962 \n",
      "Epoch:136 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:137 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.8125\n",
      "-Validation accuracy after epoc: 0.8628429174423218 \n",
      "Epoch:138 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8728179931640625 \n",
      "Epoch:139 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:140 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.852867841720581 \n",
      "Epoch:141 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8728180527687073 \n",
      "Epoch:142 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:143 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.8678305149078369 \n",
      "Epoch:144 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8628429770469666 \n",
      "Epoch:145 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:146 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8778055906295776 \n",
      "Epoch:147 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8503741025924683 \n",
      "Epoch:148 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8379052877426147 \n",
      "Epoch:149 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8578554391860962 \n",
      "Epoch:150 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:151 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8478803038597107 \n",
      "Epoch:152 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.850374162197113 \n",
      "Epoch:153 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8603492379188538 \n",
      "Epoch:154 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8628429770469666 \n",
      "Epoch:155 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8603491187095642 \n",
      "Epoch:156 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:157 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:158 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:159 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.83790522813797 \n",
      "Epoch:160 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:161 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:162 \n",
      " - Batch no: 0, train accuracy: 1.0\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:163 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.850374162197113 \n",
      "Epoch:164 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553616404533386 \n",
      "Epoch:165 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.852867841720581 \n",
      "Epoch:166 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.78125\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:167 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:168 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:169 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.90625\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8379052877426147 \n",
      "Epoch:170 \n",
      " - Batch no: 0, train accuracy: 0.875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.860349178314209 \n",
      "Epoch:171 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.96875\n",
      "-Validation accuracy after epoc: 0.8478803634643555 \n",
      "Epoch:172 \n",
      " - Batch no: 0, train accuracy: 0.84375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:173 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8703242540359497 \n",
      "Epoch:174 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8054863214492798 \n",
      "Epoch:175 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.852867841720581 \n",
      "Epoch:176 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.827930212020874 \n",
      "Epoch:177 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8678305149078369 \n",
      "Epoch:178 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 1.0\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8728179931640625 \n",
      "Epoch:179 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.9375\n",
      " - Batch no: 20, train accuracy: 1.0\n",
      "-Validation accuracy after epoc: 0.8578553795814514 \n",
      "Epoch:180 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.9375\n",
      "-Validation accuracy after epoc: 0.8603491187095642 \n",
      "Epoch:181 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.875\n",
      "-Validation accuracy after epoc: 0.8254364728927612 \n",
      "Epoch:182 \n",
      " - Batch no: 0, train accuracy: 0.90625\n",
      " - Batch no: 10, train accuracy: 0.84375\n",
      " - Batch no: 20, train accuracy: 0.84375\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:183 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8653366565704346 \n",
      "Epoch:184 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.96875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8553617000579834 \n",
      "Epoch:185 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8453865647315979 \n",
      "Epoch:186 \n",
      " - Batch no: 0, train accuracy: 0.9375\n",
      " - Batch no: 10, train accuracy: 0.875\n",
      " - Batch no: 20, train accuracy: 0.90625\n",
      "-Validation accuracy after epoc: 0.8653367161750793 \n",
      "Epoch:187 \n",
      " - Batch no: 0, train accuracy: 0.96875\n",
      " - Batch no: 10, train accuracy: 0.96875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-15918705f4d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m             sess.run(train_optimizer,feed_dict={x: batch_data[0], \n\u001b[0;32m     13\u001b[0m                                                 \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                                                 drop_prob: 0.5})\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 train_acc = accuracy.eval(feed_dict={x: batch_data[0], \n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(logdir='./Iceberg/CNNInception', graph=sess.graph)\n",
    "    for e in range(epochs):\n",
    "        n_batches = int(X_train.shape[0] / batch_size)\n",
    "        print(\"Epoch:{} \".format(e))\n",
    "        gen_train = datagen.flow(X_train, y_train,\n",
    "                                           batch_size=batch_size)\n",
    "        for batch in range(n_batches):\n",
    "            batch_data = gen_train.next()\n",
    "            sess.run(train_optimizer,feed_dict={x: batch_data[0], \n",
    "                                                y_: batch_data[1], \n",
    "                                                drop_prob: 0.5})\n",
    "            if(batch % 10 == 0):\n",
    "                train_acc = accuracy.eval(feed_dict={x: batch_data[0], \n",
    "                                                y_: batch_data[1], \n",
    "                                                drop_prob: 0.5})\n",
    "                batch_loss, summary = sess.run([train_optimizer,graph_summary],\n",
    "                                               feed_dict={x: batch_data[0], \n",
    "                                                            y_: batch_data[1], \n",
    "                                                            drop_prob: 0.5})\n",
    "                writer.add_summary(summary,global_step=global_step)\n",
    "                print(\" - Batch no: {}, train accuracy: {}\".format(batch,train_acc))\n",
    "            global_step += 1\n",
    "        valid_accuracy = accuracy.eval(feed_dict={x: X_valid, y_: y_valid, drop_prob: 1.0})\n",
    "        print(\"-Validation accuracy after epoc: {} \".format(valid_accuracy))\n",
    "    #Save your model\n",
    "    tf_saver.save(sess, save_path='./Iceberg/CNNInception/SavedModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
